<<<<<<< HEAD
---
title: "EE_Downward-Causation_Conjoint"
author: "Johannes Haehnlein"
date: "`r Sys.Date()`"
output: html_document
theme: flatly
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Overview

The following workflow analyzes the collected data of a conjoint experiment downward causation in entrepreneurial ecosystems. Downward causation is a key mechanism for understanding how EEs evolve and become self-sustaining by creating feedback loops and reinforcing themselves (Spigel, 2017; Thompson et al., 2018; Wurth et al., 2021). However, despite the importance and potential of downward causation in EEs, research on how to stimulate it remains largely obscured (Mason & Harrison, 2006; Wurth et al., 2021). Based on SET, we propose a conceptual model that examines the likelihood of EE contribution behavior as a potential function of six constructs. We propose that entrepreneurs are more likely to contribute to an EE if they have experienced support from the EE or its actors (H1), if they have strong personal relationships with other actors in the EE (H2), if they feel affiliated with the EE (H3), if they have altruistic motivation (H4), if they expect a benefit from their contribution behavior (H5) and if they perceive a potential benefit for the overall EE (H6). To investigate the proposed hypothesis we adopt a metric conjoint experiment. The data collection followed an attribute-driven and fractional factorial design, in which participants are asked to rate their likelihood of engaging in contribution behavior based on a set of hypothetical profiles that vary in terms of the six introduced attributes, each manipulated at two levels (Aiman-Smith et al., 2002; Shepherd & Zacharakis, 2018). The subsequent workflow uses established measurements and recommendations to analyze conjoint experiments (Schueler et al., 2023; Zhu et al., 2021, Shepherd & Zacharakis, 2018).

### Workflow Steps

### Sampled Data

In our study, we were explicitly interested in factors influencing the decision-making of contribution behavior. Social Exchange Theory was used as a theoretical framework to develop a model, which examines the likelihood of EE contribution behavior as a function of six constructs: reciprocity, personal relationships, affiliation, altruism, rationality, and group gain. In our conjoint experiment. Each attribute can take either a high or low level, resulting in 64 possible profiles. To reduce the number of profiles and avoid multicollinearity, we applied a fractional factorial design reducing the amount of profiles to eight.  The profiles were presented to the participants within a realistic scenario, in which they are approached by a representative of a startup center who wants to get them more involved in the EE in their region by offering them various contribution opportunities such as mentoring, coaching, guest lecturing, or keynote speaking. The participants are asked to rate their likelihood of accepting each profile on a 7-point Likert scale ranging from 1 (very unlikely) to 7 (very likely). The dependent variable is the likelihood of EE contribution behavior. After a first rating round of the eight profiles, the randomized profiles were replicated in a second round. 

We applied a purposive sampling approach focusing on entrepreneurs who have originated from an EE and are anticipated to induce downward causation. Following this framework, we target entrepreneurs who have been supported by public funding programs (e.g., EXIST in Germany) or who have been located in startup centers or participated in incubation or acceleration programs. We collected the data in two waves.

First, we approached the potential participants for our main study through various channels, such as LinkedIn and several supporting institutions from all over Germany, such as universities, incubators, and startup centers. This resulted in 90 responding entrepreneurs. Secondly we used the Prolific online survey platform, assigning the same sampling criteria. This led to additional 100 respondents. 

***

# Libraries

```{r}
library(openxlsx) # Used to import and export excel files
library(tidyverse) # Used to load all tidyverse packages
library(lavaan) # Used to perform confirmatory factor analyses
library(psych) # Used to calculate Cronbach's Alpha and ICC values
library(apaTables) # Used to create correlation tables
library(lme4) # Used for multilevel modeling 
library(lmerTest) # Used for multilevel regression adding p-values to the lme4 package
library(lmtest) # For calculating robust standard errors
library(broom) # Used to create tidy data frames with model results
library(broom.mixed) # Used to tidy result objects for multilevel modeling
library(parameters) # Used to augement regression analyses
library(performance) # Used to  obtain R2 for multilevel models
library(knitr) # Used for table creation
library(clubSandwich) # Used for cluster robust standard errors
library(sandwich) # Used for cluster robust standard errors
library(flextable) # Used for table creation
```

# Data

## Read Data

```{r}
data <- read.xlsx("Data_EE Downward Causation_Conjoint_Wave3.xlsx")
```

## Inspect Data

### Code Book

* age = Age of the subject
* gender = Gender of the subject
* education = Highest education grade
* busexp = Years of business experience of the entrepreneur
* compfound = Respondent being an entrepreneur
* amountfound = Amount fo founded companies
* compage = Years since (last) startup foundation
* compact = Ongoing activity of the entrepreneur in his startup
* role = Function of the entrepreneur in his startup
* compcity = city of company headquarters
* amountemp = Amount of employees in the entrepreneurs startup
* pubfund1 = public funding by a funding program in germany
* programpart = Participation in an accleration or incubation program
* startupcenter = Being in located in a startup or technology center
* eecontlik = Conjoint Card 1-8 (Assessment of likelihood to engage in the EE contribution behavior)
* eecontlikrep = Replication Conjoint Card 1-8 (Assessment of likelihood to engage in the EE contribution behavior)
* ee_support_reception = Perceived EE support
* ee_affiliation = Affiliation to the EE
* ee_relationships = Personal Relationship to EE actors
* altruism_potential = Altruistic potential
* positive_outcome_expectation = Expected positive outcome of the activity
* benefit_perception = Perceived benefits of the entrepreneur
* evaluation_scenexp = Experience of the described scenario
* evaluation_scenpract = Practicability of the described scenario
* evaluation_studreal = Realism of the described study
* evaluation_critund = Understandability of decision criteria
* evaluation_fun = Fun factor of the study
* ipfinvx = Intense Positive Feeling towards inventing (4 items)
* ipffndx = Intense Positive Feeling towards founding (3 items)
* ipfdev = Intense Positive Feeling towards developing (3 items)
* esex = Entrepreneurial Self-Efficacy (4 items)
* ic_inv = Identity Centrality inventing
* ic_fnd = Identity Centrality founding
* ic_dev = Identity Centrality developing
* ex_orx = Exchange Orientation (9 items)
* selfintx = Self-Interest (3 items)
* othorix = Other Orientation (3 Items)
* gentrustx = General Trust Scale (6 Items)
* bogusx = Bogus Item 1 & 3
* sudoku = Bogus Item 2
* duration = time to complete survey (min)

### Variable names

```{r}
colnames(data)
```

# Data Preparation for Analysis

## Harmonize Variable Names

```{r}
data <- data |>
  rename_all(.funs = tolower) |> # Convert all column names to lower case
  rename("role" = "function") |> # Convert variable "function" to "role"
  rename("icfnd" = "ic_icfnd") |>
  rename("icdev" = "ic_icdev") |>
  rename("icinv" = "ic_icinv") |>
  rename("pubfund" = "pubfund1") |>
  rename("scenexp" = "evaluation_scenexp") |>
  rename("scenpract" = "evaluation_scenpract") |>
  rename("studreal" = "evaluation_studreal") |>
  rename("critund" = "evaluation_critund") |>
  rename("fun" = "evaluation_fun") |>
  rowid_to_column(var = "respondent_id") # Create id column
```

## Remove effortless responses

In order to ensure data quality, respondents with low survey engagement shall be removed from the sample. To check these effortless respondents, we included three bogus items (attention checks) in our survey. We remove all respondents who failed the bogus. Also we remove respondents, who finished the survey too fast or too slow. Based on the survey's pre-test the estimated completion time was between 12 and 20 minutes. According to this, we will remove all respondents, who completed the survey in less than 8 minutes and in more than 40 minutes.

### Remove failed bogus item responses

```{r}
data <- filter(data, bogus1 == 6) # Remove all respondent failing bogus item 1
data <- filter(data, sudoku == 4) # Remove all respondent failing bogus item 2
data <- filter(data, evaluation_bogus3 == 4) # Remove all respondent failing bogus item 2
data <- filter(data, bogus3 == 4) # Remove all respondent failing bogus item 4
```

### Remove too fast or too slow conducting respondents

```{r}
duration_lower <- 8 # response time lower than 8 minutes
duration_higher <- 40 # response time higher than 40 minutes
```

```{r}
time_out_lower <- data |>
  filter(duration > duration_lower) |>
  nrow()
```

```{r}0
time_out_higher <- data |>
  filter(duration < duration_higher) |>
  nrow()
```

```{r}
data <- data |>
  filter(duration >= duration_lower) |>
  filter(duration <= duration_higher)
```

### Sample Size 

```{r}
nrow(data)
```


# Sample demographics and descriptive data

As part of our survey we collected several demographic data of the participating entrepreneurs as well as information about their personal and business background). Subsequently we select the respective data, process them to the correct formats and labels and create visualizations of the data to get an overview and summarizing information of our sample set.   

```{r}
demographics <- select(data, "age", "gender", "education", "busexp", "amountfound", "compage", "compact", "education", "role", "compcity", "amountemp", "pubfund", "programpart", "startupcenter")
```

## Processing and summarizing numerical variables

```{r}

# Calculate means, medians, sds, mins and maxs of numerical variables 

numerical_vars <- demographics |>
  select(age, busexp, amountfound, compage, amountemp) |>
  summarise_all(list(mean = ~round(mean(., na.rm = TRUE), 2), 
                     median = ~round(median(., na.rm = TRUE), 2), 
                     sd = ~round(sd(., na.rm = TRUE), 2), 
                     min = ~round(min(., na.rm = TRUE), 2), 
                     max = ~round(max(., na.rm = TRUE), 2)))


# Reshape the data
numerical_summary_long <- numerical_vars |>
  pivot_longer(cols = everything(), names_to = "variable", values_to = "value") |>
  separate(variable, into = c("variable", "statistic"), sep = "_") |>
  pivot_wider(names_from = variable, values_from = value) |>
  relocate(statistic, .before = 1)  

# Creation and Export of flextable

numerical_summary_table <- flextable(numerical_summary_long) |>
    set_header_labels(
    statistic = "Statistic",
    age = "Age",
    busexp = "Business Experience",
    amountfound = "Companies Founded",
    compage = "Company Age",
    amountemp = "Number of Employees") |>
  set_formatter(
    "Age" = ~format(round(., 2), nsmall = 2),
    "Business Experience" = ~format(round(., 2), nsmall = 2),
    "Companies Founded" = ~format(round(., 2), nsmall = 2),
    "Company Age" = ~format(round(., 2), nsmall = 2),
    "Number of Employees" = ~format(round(., 2), nsmall = 2)) |>
  set_table_properties(layout = "autofit") |>
  color(part = "header", color = "white") |>
  bg(part = "header", bg = "gray") |>
  align(align = "center", part = "all")

print(numerical_summary_table)
```

## Processing and summarizing categorical variables

```{r}

# Modify the dataframe to include categorical labels instead of coded numerical lables

demographics <- demographics |>
  mutate(
    gender = case_when(
      gender == 1 ~ "female",
      gender == 2 ~ "male",
      gender == 3 ~ "diverse"),
    education = case_when(
      education == 1 ~ "Lower Secondary Education",
      education == 2 ~ "O-level",
      education == 3 ~ "university of applied sciences entrance qualification",
      education == 4 ~ "higher education entrance qualification",
      education == 5 ~ "completed vocational training",
      education == 6 ~ "university degree",
      education == 7 ~ "Ph.D."),
    role = case_when(
      role == 1 ~ "CEO",
      role == 2 ~ "CTO",
      role == 3 ~ "COO",
      role == 4 ~ "CFO",
      role == 5 ~ "CMO",
      role == 6 ~ "General Manager",
      role == 8 ~ "Director",
      role == 9 ~ "Teamlead",
      role == 10 ~ "Other"),
    compact = if_else(compact == 1, "yes", "no"),
    pubfund = if_else(pubfund == 1, "yes", "no"),
    programpart = if_else(programpart == 1, "yes", "no"),
    startupcenter = if_else(startupcenter == 1, "yes", "no")
    )

# Calculate frequencies and percentages of the variables rounded to two decimals    

categorical_vars <- c("gender", "education", "compact", "role", 
                      "compcity", "pubfund", "programpart", "startupcenter")
categorical_summary_list <- list()

for (var in categorical_vars) {
  cat_var_table <- demographics |>
    count(!!sym(var)) |>
    mutate(percentage = round(n / sum(n) * 100, 2)) |>
    arrange(desc(n))

  categorical_summary_list[[var]] <- cat_var_table
}


# Creation of a flextable

for (var in names(categorical_summary_list)) {
  cat_table <- flextable(categorical_summary_list[[var]]) %>%
    set_table_properties(layout = "autofit") %>%
    color(part = "header", color = "white") %>%
    bg(part = "header", bg = "gray") %>%
    align(align = "center", part = "all") %>%
    autofit()

  print(cat_table)
}

```

## Evaluation of survey feedback

```{r}

# Selection of survey feedback items

survey_feedback <- select(data, "scenexp", "scenpract", "studreal", "critund", "fun")

# Calculate means, medians & sds

survey_feedback_vars <- survey_feedback |>
  select(scenexp, scenpract, studreal, critund, fun) |>
  summarise_all(list(mean = ~round(mean(., na.rm = TRUE), 2), 
                     median = ~round(median(., na.rm = TRUE), 2), 
                     sd = ~round(sd(., na.rm = TRUE), 2)))

# Reshape the data
survey_feedback_long <- survey_feedback_vars %>%
  pivot_longer(cols = everything(), names_to = "variable", values_to = "value") |>
  separate(variable, into = c("variable", "statistic"), sep = "_") |>
  pivot_wider(names_from = variable, values_from = value) |>
  relocate(statistic, .before = 1)  

# Creation and Export of flextable

survey_feedback_table <- flextable(survey_feedback_long) |>
    set_header_labels(
    statistic = "Statistic",
    scenexp = "Scenario experience",
    scenpract = "Scenario practicability",
    studreal = "Study realism",
    critund = "Criteria understandability",
    fun = "Perceived fun") |>
  set_formatter(
    "Scenario experience" = ~format(round(., 2), nsmall = 2),
    "Scenario practicability" = ~format(round(., 2), nsmall = 2),
    "Study realism" = ~format(round(., 2), nsmall = 2),
    "Criteria understandability" = ~format(round(., 2), nsmall = 2),
    "Perceived fun" = ~format(round(., 2), nsmall = 2)) |>
  set_table_properties(layout = "autofit") |>
  color(part = "header", color = "white") |>
  bg(part = "header", bg = "gray") |>
  align(align = "center", part = "all")

print(survey_feedback_table)

```

## Removal of data not being used further in the analysis 

```{r}
data <- data |>
  select(-c(scenexp)) |>
  select(-c(scenpract)) |>
  select(-c(studreal)) |>
  select(-c(critund)) |>
  select(-c(fun)) |>
  select(-c(education)) |>
  select(-c(role)) |>
  select(-c(compact)) |>
  select(-c(busexp)) |>
  select(-c(amountfound)) |>
  select(-c(compfound)) |>
  select(-c(compcity)) |>
  select(-c(bogus1)) |>
  select(-c(sudoku)) |>
  select(-c(evaluation_bogus3)) |>
  select(-c(bogus3)) |>
  select(-c(amountemp)) |>
  select(-c(duration)) 

```
















# Analysis of measured variables

To control the findings of our conjoint experiment with different potential influencing factors, we included the earlier described demographic information as well as different constructs, that theoretically could have a moderating influence. These latent variables are:

- General Trust Scale explained by 6 items (Yamagishi & Yamagishi, 1994)
- Self-Interest explained by 3 items (De Dreu & Nauta, 2009)
- Other Orientation explained by 3 items (De Dreu & Nauta, 2009)
- Exchange Orientation explained by 9 items (Clark & Mills, 2012)
- Entrepreneurial Self-Efficacy explained by 4 items (Zhao et al., 2005)
- Entrepreneurial Passion by passion for inventing (explained by 4 items for intense positive feelings towards inventing and 1 item for identity centrality for inventing), passion for founding (explained by 3 items for intense positive feelings towards founding and 1 item for identity centrality for founding) and passion for developing (explained by 3 items for intense positive feelings towards developing and 1 item for identity centrality for developing) (Cardon et al. 2013)

## Confirmatory factor analysis

Subsequently we conduct a confirmatory factor analysis (CFA) to evaluate the factor loadings on the latent vaiables and to test the model fit.

### Description of CFA model


#### CFA model (V1)

```{r}

# Score reversion of exchange orientation items as indicated by the original scales (Clark & Mills, 2012)

data <- data |>
  mutate(  exor3 = 8 - exor3,
    exor4 = 8 - exor4,
    exor5 = 8 - exor5,
    exor9 = 8 - exor9)

```



```{r}


# CFA model (V1)

cfa_model_all <- "gen_trust =~ gentrust1 + gentrust2 + gentrust1 + gentrust4 + gentrust5 + gentrust6
              self_int =~ selfint1 + selfint2 + selfint3
              oth_ori =~ othori1 + othori2 + othori3
              ex_or =~ exor1 + exor2 + exor3 + exor4 + exor5 + exor6 + exor7 + exor8 + exor9
              ese =~ ese1 + ese2 + ese3 + ese4
              ipf_inv =~ ipfinv1 + ipfinv2 + ipfinv3 + ipfinv4
              ic_inv =~ icinv
              ipf_fnd =~ ipffnd1 + ipffnd2 + ipffnd3 + ipffnd1
              ic_fnd =~ icfnd
              ipf_dev =~ ipfdev1 + ipfdev2 + ipfdev3
              ic_dev =~ icdev
              ep_inv =~ ipf_inv + ic_inv
              ep_fnd =~ ipf_fnd + ic_fnd
              ep_dev =~ ipf_dev +   ic_dev
              ep =~ ep_inv + ep_fnd + ep_dev"
                
```

#### Model fit information (V1)

```{r}

cfa_all_fit <- cfa(cfa_model_all, data = data)

summary(cfa_all_fit, fit.measures = TRUE)

```

### Standardization of results

```{r}

cfa_all_fit <- standardizedsolution(cfa_all_fit)

summary(cfa_all_fit, fit.measures = TRUE)

```

#### CFA: Results Overview in a table

```{r}

cfa_all_fit <- cfa_all_fit |>
  filter(op == "=~") |>
  select(latent_var = lhs, indicators = rhs, std_loading = est.std ) |>
  mutate(std_loading = round(std_loading, 2))

cfa_all_fit_table <- flextable(cfa_all_fit) |>
  autofit() |>
  color(part = "header", color = "white") |>
  bg(part = "header", bg = "gray") |>
  align(align = "center", part = "all") |>
  fontsize(size = 12, part = "all")

print(cfa_all_fit_table)

```



#### CFA model (V2)

```{r}

# CFA model (v2)

cfa_model <- "gen_trust =~ gentrust1 + gentrust2 + gentrust3 + gentrust4 + gentrust5 + gentrust6
              self_int =~ selfint1 + selfint2 + selfint3
              oth_ori =~ othori1 + othori2 + othori3
              ese =~ ese1 + ese2 + ese3 + ese4"

```


#### Model fit information (V2)

```{r}

cfa_fit <- cfa(cfa_model, data = data)

summary(cfa_fit, fit.measures = TRUE)

```


### Standardization of results (V2)

```{r}

cfa_fit <- standardizedsolution(cfa_fit)

summary(cfa_fit, fit.measures = TRUE)

```

### CFA: Results Overview in a table (V2)

```{r}

cfa_fit <- cfa_fit |>
  filter(op == "=~") |>
  select(latent_var = lhs, indicators = rhs, std_loading = est.std ) |>
  mutate(std_loading = round(std_loading, 2))

cfa_fit_table <- flextable(cfa_fit) |>
  autofit() |>
  color(part = "header", color = "white") |>
  bg(part = "header", bg = "gray") |>
  align(align = "center", part = "all") |>
  fontsize(size = 12, part = "all")

print(cfa_fit_table)

```


### Calculating Cronbach's alpha

Cronbach's alpha is a measure of internal consistency, that is, how closely related a set of items are as a group. It is considered to be a measure of scale reliability or consistency. A higher Cronbach's alpha value indicates greater internal consistency, often interpreted as the measure of the scale being more reliable.

```{r}

# creating scale vectors

general_trust_scale <- data[, c("gentrust1", "gentrust2", "gentrust3", "gentrust4", "gentrust5", "gentrust6")]

self_interest_scale <- data[, c("selfint1", "selfint2", "selfint3")]

other_orientation_scale <- data[, c("othori1", "othori2", "othori3")]

exchange_orientation_scale <- data[, c("exor1", "exor2", "exor3", "exor4", "exor5", "exor6", "exor7", "exor8", "exor9")]

self_efficacy_scale <- data[, c("ese1", "ese2", "ese3", "ese4")]
 
ipf_founding_scale <- data[, c("ipffnd1", "ipffnd2","ipffnd3")]

ipf_developing_scale <- data[, c("ipfdev1", "ipfdev2", "ipfdev3")]

ipf_inventing_scale <- data[, c("ipfinv1", "ipfinv2","ipfinv3","ipfinv4")]


# Computing Cronbach's alpha

alpha_general_trust_scale <- alpha(general_trust_scale)
 
alpha_self_interest_scale <- alpha(self_interest_scale)

alpha_other_orientation_scale <- alpha(other_orientation_scale)

alpha_exchange_orientation_scale <- alpha(exchange_orientation_scale)

alpha_self_efficacy_scale <- alpha(self_efficacy_scale)

alpha_ipf_founding_scale <- alpha(ipf_founding_scale)

alpha_ipf_developing_scale <- alpha(ipf_developing_scale)

alpha_ipf_inventing_scale <- alpha(ipf_inventing_scale)



# Displaying summary of Cronbach's Alpha for each scale

alpha_results <- data(
  Scale = c("General Trust", "Self Interest", "Other Orientation", 
            "Exchange Orientation", "Self Efficacy", "IPF Founding", 
            "IPF Developing", "IPF Inventing", "EP Founding", "EP Developing", "EP Inventing", "EP"),
  Cronbachs_Alpha = c(alpha_general_trust_scale$total$raw_alpha,
                      alpha_self_interest_scale$total$raw_alpha,
                      alpha_other_orientation_scale$total$raw_alpha,
                      alpha_exchange_orientation_scale$total$raw_alpha,
                      alpha_self_efficacy_scale$total$raw_alpha,
                      alpha_ipf_founding_scale$total$raw_alpha,
                      alpha_ipf_developing_scale$total$raw_alpha,
                      alpha_ipf_inventing_scale$total$raw_alpha,
                      ))

# Print the summary table
print(alpha_results)

```




## Aggregation of indicators to composites

### Calculating the composites

```{r}
data <- data |>
  rowwise() |>
  mutate(gen_trust = mean(c(gentrust1, gentrust2, gentrust3, gentrust4, gentrust5, gentrust6))) |>
  mutate(self_int = mean(c(selfint1, selfint2, selfint3))) |>
  mutate(oth_ori = mean(c(othori1, othori2, othori3))) |>
  mutate(ex_or = mean(c(exor1, exor2, exor3, exor4, exor5, exor6, exor7, exor8, exor9))) |>
  mutate(ese = mean(c(ese1, ese2, ese3, ese4))) |>
  mutate(ipf_inv = mean(c(ipfinv1, ipfinv2, ipfinv3, ipfinv4))) |>
  mutate(ic_inv = mean(c(icinv))) |>
  mutate(ipf_dev = mean(c(ipfdev1, ipfdev2, ipfdev3))) |>
  mutate(ic_dev = mean(c(icdev))) |>
  mutate(ipf_fnd = mean(c(ipffnd1, ipffnd2, ipffnd3))) |>
  mutate(ic_fnd = mean(c(icfnd))) |>
  mutate(ep_inv = mean(c(ipf_inv, ic_inv))) |>
  mutate(ep_fnd = mean(c(ipf_fnd, ic_fnd))) |>
  mutate(ep_dev = mean(c(ipf_dev, ic_dev))) |>
  mutate(ep = mean(c(ep_inv, ep_fnd, ep_dev))) |>
  ungroup()
  
```


### Removing the indicators from the dataset

```{r}

data <- data |>
  select(-c(gentrust1, gentrust2, gentrust3, gentrust4, gentrust5, gentrust6)) |>
  select(-c(selfint1, selfint2, selfint3)) |>
  select(-c(othori1, othori2, othori3)) |>
  select(-c(exor1, exor2, exor3, exor4, exor5, exor6, exor7, exor8, exor9)) |>
  select(-c(ese1, ese2, ese3, ese4)) |>
  select(-c(ipfinv1, ipfinv2, ipfinv3, ipfinv4)) |>
  select(-c(icinv)) |>
  select(-c(ipfdev1, ipfdev2, ipfdev3)) |>
  select(-c(icdev)) |>
  select(-c(ipffnd1, ipffnd2, ipffnd3)) |>
  select(-c(icfnd)) 

```













# Conjoint experiment

## Fractional Factorial Design 

Here, we provide you with the factorial design of this conjoint study: Subsequently the factorial design of the conducted conjoint study will be explained: 

  * 6 attributes
    **ee_support_reception = Perceived EE support
    **ee_affiliation = Affiliation to the EE
    **ee_relationships = Personal Relationship to EE actors
    **altruism_potential = Altruistic potential
    **positive_outcome_expectation = Expected positive outcome of the activity
    **benefit_perception = Perceived benefits of the entrepreneur
  * 2 levels per attribute (0 = low; 1 = high)
  * Fractional design with main-effects only  -> 8 profiles
  * Full replication of all 8 profiles -> 16 profiles
  * Dependent variable = eecontlikex = likelihood to engage in the EE contribution behavior

```{r}
# Levels of all 8 profiles (Orthoplan)

profiles <- tibble(
  profile = c(1, 2, 3, 4, 5, 6, 7, 8),
  ee_support_reception = c(1, 0, 1, 0, 0, 1, 0, 1),
  ee_affiliation = c(0, 1, 1, 0, 1, 0, 0, 1),
  ee_relationships = c(0, 1, 0, 0, 0, 1, 1, 1),
  altruism_potential = c(0, 0, 1, 1, 0, 0, 1, 1),
  positive_outcome_expectation = c(0, 0, 0, 1, 1, 1, 0, 1),
  benefit_perception = c(1, 1, 0, 1, 0, 0, 0, 1)
)
```

### First round of data collection in the conjoint experiment

  *Included variables:
    **respondent_id
    **age
    **gender
    **pubfund
    **programpart
    **startupcenter
    **eecontlike1 to eecontlike8
    **[CFA Factors]


```{r}

first_round_data <- data |>
  select(1:15, 24:26, 28) # Selecting data from first collection round

first_round_data <- first_round_data |>
  pivot_longer(!c(1:7, 16:19), # pivoting the data set to a long format
    names_to = "profile", # bringing profile numbers to profile column
    values_to = "eecontlike") |> # bringing eecontlike values to eecontlike column
  mutate(profile = as.numeric(str_extract(profile, "\\-*\\d+\\.*\\d*"))) |> # saving numeric values of profile numbers into the profile column
  mutate(round_id = 1) |> # adding round 1 id
  relocate(round_id, profile, eecontlike, .after = respondent_id) # adjusting column order

```

### Second round of data collection in the conjoint experiment

  *Included variables:
    **respondent_id
    **age
    **gender
    **pubfund
    **programpart
    **startupcenter
    **eecontlike1rep to eecontlike8rep
    **[CFA Factors]


```{r}

second_round_data <- data |>
  select(1:7, 16:23, 24:26, 28) # Selecting data from second collection round

second_round_data <- second_round_data |>
  pivot_longer(!c(1:7, 16:19), # pivoting the data set to a long format
    names_to = "profile", # bringing profile numbers to profile column
    values_to = "eecontlike") |> # bringing eecontlike values to eecontlike column
  mutate(profile = as.numeric(str_extract(profile, "\\-*\\d+\\.*\\d*"))) |> # saving numeric values of profile numbers into the profile column
  mutate(round_id = 2) |> # adding round 1 id
  relocate(round_id, profile, eecontlike, .after = respondent_id) # adjusting column order

```

### Merging both reounds of data collection

```{r}
data <- rbind(first_round_data, second_round_data)
```

### Merging factorial design

```{r}
data <- left_join(data, profiles, by = "profile") |> 
  relocate("ee_support_reception", "ee_affiliation", "ee_relationships", "altruism_potential", "positive_outcome_expectation", "benefit_perception", .after = "profile") #relocating attributes in the data set

```

### Converting id and round variables from a numeric format into factors

```{r}

data <- data |>
   mutate(respondent_id = as_factor(respondent_id)) |>
   mutate(round_id = as_factor(round_id))

```



## Correlation Table

The correlation table of the model includes the dependent variable, controls as well as significant factors from the CFA. These are:

  *eecontlike
  *age
  *gender
  *compage
  *pubfund
  *programpart
  *startupcenter
  *gen_trust
  *self_int
  *oth_ori
  *ese
 


```{r}

data |>
  select(eecontlike, age, gender, compage, pubfund, programpart, gen_trust, self_int, oth_ori, ese) |> #selecting variables
  apa.cor.table() #creation of correlation matrix

```


## Evaluation of data consistency & regression model

As already explained earlier, our conjoint experiment included the following theoretically derived 6 attributes:

* Dependent variable: eecontlike = likelihood to engage in the EE contribution behavior
* Independent variables:
    **ee_support_reception = Perceived EE support
    **ee_affiliation = Affiliation to the EE
    **ee_relationships = Personal Relationship to EE actors
    **altruism_potential = Altruistic potential
    **positive_outcome_expectation = Expected positive outcome of the activity
    **benefit_perception = Perceived benefits of the entrepreneur

Due to the nature of conjoint studies with complex and theoretically derived scenarios, the potential uncertainity, ambiguity and eventually careless responses is high (Lohrke, 2010). In order to test response consistency, we replicated all 8 profiles of our fractional factorial design (Shepherd & Zacharakis, 2018). Using the data sets from both data collection rounds, we can test the stability of responses applying test-retest reliability assesment.

To evaluate test-retest reliability, we follow the subsequent workflow proposed by Schueler et al. (2023):

1. Calculation of the Intraclass Correlation Coefficient (ICC) for each decision profile
2. Estimation of a linear model with clustered standard errors
3. Calculation of a slope difference test for each parameter
4. Specification of a fully pooled model using both rounds of data with two-way clustered standard errors for both, round and respondent as well as multilevel model to check the results.


We will include the earlier specified and listed variables in the regression model.


### Step 1: Calculation of ICC Values for Each Profile

#### Profile 1

##### Profile 1: Transfering data from long to wide format

```{r}

profile1_data <- data |>
  filter(profile == 1) |>
  select(respondent_id, round_id, eecontlike) |> 
  pivot_wider(id_cols = respondent_id, names_prefix = "Round", 
              names_from = round_id, values_from = eecontlike) |>
  select(-respondent_id)

```

##### Profile 1: Calculating ICC (3,k)

```{r}

profile1_icc <- ICC(profile1_data)$results |> 
  filter(type == "ICC3k") |> 
  select(ICC, "lower bound", "upper bound") |>  
  mutate_all(round, 2) %>% 
  remove_rownames(.) %>% 
  add_column(Profile = "Profile 1", .before = "ICC")
profile1_icc

```


#### Profile 2

##### Profile 2: Transfering data from long to wide format

```{r}

profile2_data <- data |>
  filter(profile == 2) |>
  select(respondent_id, round_id, eecontlike) |> 
  pivot_wider(id_cols = respondent_id, names_prefix = "Round", 
              names_from = round_id, values_from = eecontlike) |>
  select(-respondent_id)
```

##### Profile 2: Calculating ICC (3,k)

```{r}

profile2_icc <- ICC(profile2_data)$results |> 
  filter(type == "ICC3k") |> 
  select(ICC, "lower bound", "upper bound") |>  
  mutate_all(round, 2) %>%  
  remove_rownames(.) %>% 
  add_column(Profile = "Profile 2", .before = "ICC")
profile2_icc

```

#### Profile 3

##### Profile 3: Transfering data from long to wide format

```{r}

profile3_data <- data |>
  filter(profile == 3) |>
  select(respondent_id, round_id, eecontlike) |> 
  pivot_wider(id_cols = respondent_id, names_prefix = "Round", 
              names_from = round_id, values_from = eecontlike) |>
  select(-respondent_id)
```

##### Profile 3: Calculating ICC (3,k)

```{r}

profile3_icc <- ICC(profile3_data)$results |> 
  filter(type == "ICC3k") |> 
  select(ICC, "lower bound", "upper bound") |>  
  mutate_all(round, 2) %>%
  remove_rownames(.) %>% 
  add_column(Profile = "Profile 3", .before = "ICC")
profile3_icc

```

#### Profile 4

##### Profile 4: Transfering data from long to wide format

```{r}

profile4_data <- data |>
  filter(profile == 4) |>
  select(respondent_id, round_id, eecontlike) |> 
  pivot_wider(id_cols = respondent_id, names_prefix = "Round", 
              names_from = round_id, values_from = eecontlike) |>
  select(-respondent_id)
```

##### Profile 4: Calculating ICC (3,k)

```{r}

profile4_icc <- ICC(profile4_data)$results |> 
  filter(type == "ICC3k") |> 
  select(ICC, "lower bound", "upper bound") |>  
  mutate_all(round, 2) %>%  
  remove_rownames(.) %>% 
  add_column(Profile = "Profile 4", .before = "ICC")
profile4_icc

```

#### Profile 5

##### Profile 5: Transfering data from long to wide format

```{r}

profile5_data <- data |>
  filter(profile == 5) |>
  select(respondent_id, round_id, eecontlike) |> 
  pivot_wider(id_cols = respondent_id, names_prefix = "Round", 
              names_from = round_id, values_from = eecontlike) |>
  select(-respondent_id)
```

##### Profile 5: Calculating ICC (3,k)

```{r}

profile5_icc <- ICC(profile5_data)$results |> 
  filter(type == "ICC3k") |> 
  select(ICC, "lower bound", "upper bound") |>  
  mutate_all(round, 2) %>%  
  remove_rownames(.) %>% 
  add_column(Profile = "Profile 5", .before = "ICC")
profile5_icc

```

#### Profile 6

##### Profile 6: Transfering data from long to wide format

```{r}

profile6_data <- data |>
  filter(profile == 6) |>
  select(respondent_id, round_id, eecontlike) |> 
  pivot_wider(id_cols = respondent_id, names_prefix = "Round", 
              names_from = round_id, values_from = eecontlike) |>
  select(-respondent_id)
```

##### Profile 6: Calculating ICC (3,k)

```{r}

profile6_icc <- ICC(profile6_data)$results |> 
  filter(type == "ICC3k") |> 
  select(ICC, "lower bound", "upper bound") |>  
  mutate_all(round, 2) %>%  
  remove_rownames(.) %>% 
  add_column(Profile = "Profile 6", .before = "ICC")
profile6_icc

```

#### Profile 7

##### Profile 7: Transfering data from long to wide format

```{r}

profile7_data <- data |>
  filter(profile == 7) |>
  select(respondent_id, round_id, eecontlike) |> 
  pivot_wider(id_cols = respondent_id, names_prefix = "Round", 
              names_from = round_id, values_from = eecontlike) |>
  select(-respondent_id)
```

##### Profile 7: Calculating ICC (3,k)

```{r}

profile7_icc <- ICC(profile7_data)$results |> 
  filter(type == "ICC3k") |> 
  select(ICC, "lower bound", "upper bound") |>  
  mutate_all(round, 2) %>% 
  remove_rownames(.) %>% 
  add_column(Profile = "Profile 7", .before = "ICC")
profile7_icc

```

#### Profile 8

##### Profile 8: Transfering data from long to wide format

```{r}

profile8_data <- data |>
  filter(profile == 8) |>
  select(respondent_id, round_id, eecontlike) |> 
  pivot_wider(id_cols = respondent_id, names_prefix = "Round", 
              names_from = round_id, values_from = eecontlike) |>
  select(-respondent_id)
```

##### Profile 8: Calculating ICC (3,k)

```{r}

profile8_icc <- ICC(profile8_data)$results |> 
  filter(type == "ICC3k") |> 
  select(ICC, "lower bound", "upper bound") |>  
  mutate_all(round, 2) %>%  
  remove_rownames(.) %>% 
  add_column(Profile = "Profile 8", .before = "ICC")
profile8_icc

```

#### ICC Summary Table

The summary table includes the ICC value itself and a 95% confidence interval to better understand the underlying variance in response consistency. 

```{r}
# We collect all the previous rounds to display in a single data frame/table
bind_rows(profile1_icc,
          profile2_icc,
          profile3_icc,
          profile4_icc,
          profile5_icc,
          profile6_icc,
          profile7_icc,
          profile8_icc)
```



### Step 2: Linear Model with clustered standard errors

In this step we calculate a simple linear model for each round of data, capture those results, and display them in a table. The purpose of this step is to capture the parameter estimates (beta coefficients) to use for the slope difference test. 

#### First Round

##### First Round Data

```{r}
# Filtering the data set first round data and convert the ID into a factor
first_round_data <- data |> 
  filter(round_id == 1) |> 
  mutate(respondent_id = as_factor(respondent_id))

```

##### First Round Model

```{r}
# Fitting the model
first_round_model <- lm(eecontlike ~ ee_support_reception + ee_affiliation + ee_relationships + altruism_potential + positive_outcome_expectation + benefit_perception, data = first_round_data)

# Calculating clustered standard errors
first_round_cluster <- coeftest(first_round_model, vcov = vcovCL, cluster = ~ respondent_id)

# Displaying results
tidy(first_round_cluster) |> 
  select(term, estimate, std.error)
```

##### Capturing Model Parameters (First Round)

```{r}
# Extracting relevant information from the model's results and format it as a table
first_round_est <- tidy(first_round_cluster) |> 
  select(term, estimate, std.error) |>  
  rename(IV = "term", Beta_first = "estimate", SE_first = "std.error")
```


#### Second Round (Replication)

##### Second Round Data

```{r}
second_round_data <- data %>% 
  filter(round_id == 2) %>% 
  mutate(respondent_id = as_factor(respondent_id))
```

##### Second Round Model

```{r}

# Fitting the model
second_round_model <- lm(eecontlike ~ ee_support_reception + ee_affiliation + ee_relationships + altruism_potential + positive_outcome_expectation + benefit_perception, data = second_round_data)

# Calculating clustered standard errors
second_round_cluster <- coeftest(second_round_model, vcov = vcovCL, cluster = ~ respondent_id)

# Displaying results
tidy(second_round_cluster) |> 
  select(term, estimate, std.error)

```

##### Capturing Model Parameters (Second Round)

```{r}
# Extracting relevant information from the model's results and format it as a table
second_round_est <- tidy(second_round_cluster) |> 
  select(estimate, std.error) |>  
  rename(Beta_second = "estimate", SE_second = "std.error")

```


#### Display Both Model Results

```{r}
# Combine the results of both models into a single data frame and display 
#  as a table
both_rounds_models_est <- bind_cols(first_round_est, second_round_est)

both_rounds_models_est

```

#### Step 3: Slope Difference Test

Evaluate consistency across estimated models using the first round of data collection and the second round.
We use the process outlined by Gelman and Stern (2006) to test for a statistically significant difference between the estimate of each independent variable beta in the first round model and that in second round model. This is a simple test to evaluate whether two studies using the same instrument and similar assumptions about the population of interest (e.g., similar random draws) produce statistically similar results. 

Here we use the test to evaluate consistency across estimated models using the initial round of data collection and the replication round. Random variation suggests that there will be differences between the two rounds; the question for researchers is whether this variation is statistically meaningful. Even in the case of relatively low test-retest reliability, researchers may still have confidence reporting results should the models produce similar results---giving credibility to the conclusion that random variation is responsible for small differences as opposed to a more systematic concern. 



```{r}
both_rounds_models_std <- both_rounds_models_est |> 
  mutate(Beta_diff = Beta_first - Beta_second,
         Joint_se = round(sqrt((SE_first^2) + (SE_second^2)), 2),
         Test_statistic = abs(Beta_diff) - (2 * Joint_se),
         Stat_diff = case_when(Test_statistic >= 0 ~ "Yes", 
                               Test_statistic < 0 ~ "No")) |>  
  mutate(across(where(is.double), round, 2))

both_rounds_models_std
```


### Step 4: Pooled Model

In our last step, we advocate for estimating a pooled model that would include both rounds of data collection. The intent here is to improve consistency of the parameter estimates by taking advantage of the pooling and shrinkage inherent to these models, and to also improve consistency of inference by lowering the estimated standard errors (see Gelman, 2006). 

Subsequently we use a pooled model to test the study's research question.

#### Pooled Data

```{r}

# Converting round_id and respondent_id into a factor to correct the standard errors for clustering by round and by respondent
pooled_data <- data |> 
  mutate(round_id = as_factor(round_id),
         respondent_id = as_factor(respondent_id))

```

#### Pooled Regression Model

```{r}

# Fitting the model
pooled_model <- lm(eecontlike ~ ee_support_reception + ee_affiliation + ee_relationships + altruism_potential + positive_outcome_expectation + benefit_perception, data = pooled_data)

# Calculating clustered standard errors at the respondent and round levels
pooled_cluster <- coeftest(pooled_model, vcov = vcovCL, cluster = ~ respondent_id + round_id)

# Displaying the results
tidy(pooled_cluster) |>
  select(term, estimate, std.error)

```

#### Reporting model

```{r}

# Extracting model fit statistics
pooled_model_fit <- glance(pooled_model)

# Displaying the results
pooled_model_fit

# Creating a fit table
model_fit_table <- tibble(
  `R-Squared` = round(pooled_model_fit$r.squared, 2),
  `Adjusted R-Squared` = round(pooled_model_fit$adj.r.squared, 2),
  `Sigma` = round(pooled_model_fit$sigma, 2),
  `F-Statistic` = round(pooled_model_fit$statistic, 2),
  `p-value` = round(pooled_model_fit$p.value, 2),
)

# Displaying the fit table
model_fit_table

```


#### Multilevel Model (Comparison)


```{r}

# Fitting the model
multilevel_model <- lmer(eecontlike ~ ee_support_reception + ee_affiliation + ee_relationships + altruism_potential + positive_outcome_expectation + benefit_perception + (1 | respondent_id) + (1 | round_id), 
                         data = pooled_data)

# Displaying the results
tidy(multilevel_model, effects = "fixed") |> 
  select(term, estimate, std.error)
```






#### Pooled Regression Model (adding controls & moderation testing)

```{r}

# Fitting the model
pooled_model_2 <- lm(
  eecontlike ~ ee_support_reception + ee_affiliation + ee_relationships + 
    altruism_potential + positive_outcome_expectation + benefit_perception + 
    age + gender + pubfund + programpart + compage + gen_trust + oth_ori + self_int + ese, 
    data = pooled_data )

# Calculating clustered standard errors at the respondent and round levels
pooled_cluster_2 <- coeftest(pooled_model_2, vcov = vcovCL, cluster = ~ respondent_id + round_id)

# Displaying the results
tidy(pooled_cluster_2) |>
  select(term, estimate, std.error)

```

#### Reporting model

```{r}

# Extracting model fit statistics
pooled_model_2_fit <- glance(pooled_model_2)

# Displaying the results
pooled_model_2_fit

# Creating a fit table
model_fit_2_table <- tibble(
  `R-Squared` = round(pooled_model_2_fit$r.squared, 2),
  `Adjusted R-Squared` = round(pooled_model_2_fit$adj.r.squared, 2),
  `Sigma` = round(pooled_model_2_fit$sigma, 2),
  `F-Statistic` = round(pooled_model_2_fit$statistic, 2),
  `p-value` = round(pooled_model_2_fit$p.value, 2),
)

# Displaying the fit table
model_fit_2_table

```


























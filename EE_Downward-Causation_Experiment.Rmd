<<<<<<< HEAD
---
title: "EE_Downward-Causation_Conjoint"
author: "Johannes Haehnlein"
date: "`r Sys.Date()`"
output: html_document
theme: flatly
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Overview

The following workflow analyzes the collected data of a conjoint experiment downward causation in entrepreneurial ecosystems. Downward causation is a key mechanism for understanding how EEs evolve and become self-sustaining by creating feedback loops and reinforcing themselves (Spigel, 2017; Thompson et al., 2018; Wurth et al., 2021). However, despite the importance and potential of downward causation in EEs, research on how to stimulate it remains largely obscured (Mason & Harrison, 2006; Wurth et al., 2021). Based on SET, we propose a conceptual model that examines the likelihood of EE contribution behavior as a potential function of six constructs. We propose that entrepreneurs are more likely to contribute to an EE if they have experienced support from the EE or its actors (H1), if they have strong personal relationships with other actors in the EE (H2), if they feel affiliated with the EE (H3), if they have altruistic motivation (H4), if they expect a benefit from their contribution behavior (H5) and if they perceive a potential benefit for the overall EE (H6). To investigate the proposed hypothesis we adopt a metric conjoint experiment. The data collection followed an attribute-driven and fractional factorial design, in which participants are asked to rate their likelihood of engaging in contribution behavior based on a set of hypothetical profiles that vary in terms of the six introduced attributes, each manipulated at two levels (Aiman-Smith et al., 2002; Shepherd & Zacharakis, 2018). The subsequent workflow uses established measurements and recommendations to analyze conjoint experiments (Schueler et al., 2023; Zhu et al., 2021, Shepherd & Zacharakis, 2018).

### Workflow Steps

### Sampled Data

In our study, we were explicitly interested in factors influencing the decision-making of contribution behavior. Social Exchange Theory was used as a theoretical framework to develop a model, which examines the likelihood of EE contribution behavior as a function of six constructs: reciprocity, personal relationships, affiliation, altruism, rationality, and group gain. In our conjoint experiment. Each attribute can take either a high or low level, resulting in 64 possible profiles. To reduce the number of profiles and avoid multicollinearity, we applied a fractional factorial design reducing the amount of profiles to eight.  The profiles were presented to the participants within a realistic scenario, in which they are approached by a representative of a startup center who wants to get them more involved in the EE in their region by offering them various contribution opportunities such as mentoring, coaching, guest lecturing, or keynote speaking. The participants are asked to rate their likelihood of accepting each profile on a 7-point Likert scale ranging from 1 (very unlikely) to 7 (very likely). The dependent variable is the likelihood of EE contribution behavior. After a first rating round of the eight profiles, the randomized profiles were replicated in a second round. 

We applied a purposive sampling approach focusing on entrepreneurs who have originated from an EE and are anticipated to induce downward causation. Following this framework, we target entrepreneurs who have been supported by public funding programs (e.g., EXIST in Germany) or who have been located in startup centers or participated in incubation or acceleration programs. We collected the data in two waves.

First, we approached the potential participants for our main study through various channels, such as LinkedIn and several supporting institutions from all over Germany, such as universities, incubators, and startup centers. This resulted in 90 responding entrepreneurs. Secondly we used the Prolific online survey platform, assigning the same sampling criteria. This led to additional 100 respondents. 

***

# Libraries

```{r}
library(openxlsx) # Used to import and export excel files
library(tidyverse) # Used to load all tidyverse packages
library(lavaan) # Used to perform confirmatory factor analyses
library(psych) # Used to calculate Cronbach's Alpha and ICC values
library(apaTables) # Used to create correlation tables
library(lme4) # Used for multilevel modeling 
library(lmerTest) # Used for multilevel regression adding p-values to the lme4 package
library(lmtest) # For calculating robust standard errors
library(broom) # Used to create tidy data frames with model results
library(broom.mixed) # Used to tidy result objects for multilevel modeling
library(parameters) # Used to augement regression analyses
library(performance) # Used to  obtain R2 for multilevel models
library(knitr) # Used for table creation
library(clubSandwich) # Used for cluster robust standard errors
library(sandwich) # Used for cluster robust standard errors
library(flextable) # Used for table creation
```

# Data

## Read Data

```{r}
data <- read.xlsx("Data_EE Downward Causation_Conjoint_Wave2.xlsx")
```

## Inspect Data

### Code Book

* age = Age of the subject
* gender = Gender of the subject
* education = Highest education grade
* busexp = Years of business experience of the entrepreneur
* compfound = Respondent being an entrepreneur
* amountfound = Amount fo founded companies
* compage = Years since (last) startup foundation
* compact = Ongoing activity of the entrepreneur in his startup
* role = Function of the entrepreneur in his startup
* compcity = city of company headquarters
* amountemp = Amount of employees in the entrepreneurs startup
* pubfund1 = public funding by a funding program in germany
* programpart = Participation in an accleration or incubation program
* startupcenter = Being in located in a startup or technology center
* eecontlik = Conjoint Card 1-8 (Assessment of likelihood to engage in the EE contribution behavior)
* eecontlikrep = Replication Conjoint Card 1-8 (Assessment of likelihood to engage in the EE contribution behavior)
* ee_support_reception = Perceived EE support
* ee_affiliation = Affiliation to the EE
* ee_relationships = Personal Relationship to EE actors
* altruism_potential = Altruistic potential
* positive_outcome_expectation = Expected positive outcome of the activity
* benefit_perception = Perceived benefits of the entrepreneur
* evaluation_scenexp = Experience of the described scenario
* evaluation_scenpract = Practicability of the described scenario
* evaluation_studreal = Realism of the described study
* evaluation_critund = Understandability of decision criteria
* evaluation_fun = Fun factor of the study
* ipfinvx = Intense Positive Feeling towards inventing (4 items)
* ipffndx = Intense Positive Feeling towards founding (3 items)
* ipfdev = Intense Positive Feeling towards developing (3 items)
* esex = Entrepreneurial Self-Efficacy (4 items)
* ic_inv = Identity Centrality inventing
* ic_fnd = Identity Centrality founding
* ic_dev = Identity Centrality developing
* ex_orx = Exchange Orientation (9 items)
* selfintx = Self-Interest (3 items)
* othorix = Other Orientation (3 Items)
* gentrustx = General Trust Scale (6 Items)
* bogusx = Bogus Item 1 & 3
* sudoku = Bogus Item 2
* duration = time to complete survey (min)

### Variable names

```{r}
colnames(data)
```

# Data Preparation for Analysis

## Harmonize Variable Names

```{r}
data <- data |>
  rename_all(.funs = tolower) |> # Convert all column names to lower case
  rename("role" = "function") |> # Convert variable "function" to "role"
  rename("icfnd" = "ic_icfnd") |>
  rename("icdev" = "ic_icdev") |>
  rename("icinv" = "ic_icinv") |>
  rename("pubfund" = "pubfund1") |>
  rename("scenexp" = "evaluation_scenexp") |>
  rename("scenpract" = "evaluation_scenpract") |>
  rename("studreal" = "evaluation_studreal") |>
  rename("critund" = "evaluation_critund") |>
  rename("fun" = "evaluation_fun") |>
  rowid_to_column(var = "respondent_id") # Create id column
```

## Remove effortless responses

In order to ensure data quality, respondents with low survey engagement shall be removed from the sample. To check these effortless respondents, we included three bogus items (attention checks) in our survey. We remove all respondents who failed the bogus. Also we remove respondents, who finished the survey too fast or too slow. Based on the survey's pre-test the estimated completion time was between 12 and 20 minutes. According to this, we will remove all respondents, who completed the survey in less than 8 minutes and in more than 40 minutes.

### Remove failed bogus item responses

```{r}
data <- filter(data, bogus1 == 6) # Remove all respondent failing bogus item 1
data <- filter(data, sudoku == 4) # Remove all respondent failing bogus item 2
data <- filter(data, evaluation_bogus3 == 4) # Remove all respondent failing bogus item 2
data <- filter(data, bogus3 == 4) # Remove all respondent failing bogus item 4
```

### Remove too fast or too slow conducting respondents

```{r}
duration_lower <- 8 # response time lower than 8 minutes
duration_higher <- 40 # response time higher than 40 minutes
```

```{r}
time_out_lower <- data |>
  filter(duration > duration_lower) |>
  nrow()
```

```{r}0
time_out_higher <- data |>
  filter(duration < duration_higher) |>
  nrow()
```

```{r}
data <- data |>
  filter(duration >= duration_lower) |>
  filter(duration <= duration_higher)
```

### Sample Size (Wave 1)

```{r}
nrow(data)
```


# Sample demographics and descriptive data

As part of our survey we collected several demographic data of the participating entrepreneurs as well as information about their personal and business background). Subsequently we select the respective data, process them to the correct formats and labels and create visualizations of the data to get an overview and summarizing information of our sample set.   

```{r}
demographics <- select(data, "age", "gender", "education", "busexp", "amountfound", "compage", "compact", "education", "role", "compcity", "amountemp", "pubfund", "programpart", "startupcenter")
```

## Processing and summarizing numerical variables

```{r}

# Calculate means, medians, sds, mins and maxs of numerical variables 

numerical_vars <- demographics |>
  select(age, busexp, amountfound, compage, amountemp) |>
  summarise_all(list(mean = ~round(mean(., na.rm = TRUE), 2), 
                     median = ~round(median(., na.rm = TRUE), 2), 
                     sd = ~round(sd(., na.rm = TRUE), 2), 
                     min = ~round(min(., na.rm = TRUE), 2), 
                     max = ~round(max(., na.rm = TRUE), 2)))


# Reshape the data
numerical_summary_long <- numerical_vars |>
  pivot_longer(cols = everything(), names_to = "variable", values_to = "value") |>
  separate(variable, into = c("variable", "statistic"), sep = "_") |>
  pivot_wider(names_from = variable, values_from = value) |>
  relocate(statistic, .before = 1)  

# Creation and Export of flextable

numerical_summary_table <- flextable(numerical_summary_long) |>
    set_header_labels(
    statistic = "Statistic",
    age = "Age",
    busexp = "Business Experience",
    amountfound = "Companies Founded",
    compage = "Company Age",
    amountemp = "Number of Employees") |>
  set_formatter(
    "Age" = ~format(round(., 2), nsmall = 2),
    "Business Experience" = ~format(round(., 2), nsmall = 2),
    "Companies Founded" = ~format(round(., 2), nsmall = 2),
    "Company Age" = ~format(round(., 2), nsmall = 2),
    "Number of Employees" = ~format(round(., 2), nsmall = 2)) |>
  set_table_properties(layout = "autofit") |>
  color(part = "header", color = "white") |>
  bg(part = "header", bg = "gray") |>
  align(align = "center", part = "all")

print(numerical_summary_table)
```

## Processing and summarizing categorical variables

```{r}

# Modify the dataframe to include categorical labels instead of coded numerical lables

demographics <- demographics |>
  mutate(
    gender = case_when(
      gender == 1 ~ "female",
      gender == 2 ~ "male",
      gender == 3 ~ "diverse"),
    education = case_when(
      education == 1 ~ "Lower Secondary Education",
      education == 2 ~ "O-level",
      education == 3 ~ "university of applied sciences entrance qualification",
      education == 4 ~ "higher education entrance qualification",
      education == 5 ~ "completed vocational training",
      education == 6 ~ "university degree",
      education == 7 ~ "Ph.D."),
    role = case_when(
      role == 1 ~ "CEO",
      role == 2 ~ "CTO",
      role == 3 ~ "COO",
      role == 4 ~ "CFO",
      role == 5 ~ "CMO",
      role == 6 ~ "General Manager",
      role == 8 ~ "Director",
      role == 9 ~ "Teamlead",
      role == 10 ~ "Other"),
    compact = if_else(compact == 1, "yes", "no"),
    pubfund = if_else(pubfund == 1, "yes", "no"),
    programpart = if_else(programpart == 1, "yes", "no"),
    startupcenter = if_else(startupcenter == 1, "yes", "no")
    )

# Calculate frequencies and percentages of the variables rounded to two decimals    

categorical_vars <- c("gender", "education", "compact", "role", 
                      "compcity", "pubfund", "programpart", "startupcenter")
categorical_summary_list <- list()

for (var in categorical_vars) {
  cat_var_table <- demographics |>
    count(!!sym(var)) |>
    mutate(percentage = round(n / sum(n) * 100, 2)) |>
    arrange(desc(n))

  categorical_summary_list[[var]] <- cat_var_table
}


# Creation of a flextable

for (var in names(categorical_summary_list)) {
  cat_table <- flextable(categorical_summary_list[[var]]) %>%
    set_table_properties(layout = "autofit") %>%
    color(part = "header", color = "white") %>%
    bg(part = "header", bg = "gray") %>%
    align(align = "center", part = "all") %>%
    autofit()

  print(cat_table)
}

```

## Evaluation of survey feedback

```{r}

# Selection of survey feedback items

survey_feedback <- select(data, "scenexp", "scenpract", "studreal", "critund", "fun")

# Calculate means, medians & sds

survey_feedback_vars <- survey_feedback |>
  select(scenexp, scenpract, studreal, critund, fun) |>
  summarise_all(list(mean = ~round(mean(., na.rm = TRUE), 2), 
                     median = ~round(median(., na.rm = TRUE), 2), 
                     sd = ~round(sd(., na.rm = TRUE), 2)))

# Reshape the data
survey_feedback_long <- survey_feedback_vars %>%
  pivot_longer(cols = everything(), names_to = "variable", values_to = "value") |>
  separate(variable, into = c("variable", "statistic"), sep = "_") |>
  pivot_wider(names_from = variable, values_from = value) |>
  relocate(statistic, .before = 1)  

# Creation and Export of flextable

survey_feedback_table <- flextable(survey_feedback_long) |>
    set_header_labels(
    statistic = "Statistic",
    scenexp = "Scenario experience",
    scenpract = "Scenario practicability",
    studreal = "Study realism",
    critund = "Criteria understandability",
    fun = "Perceived fun") |>
  set_formatter(
    "Scenario experience" = ~format(round(., 2), nsmall = 2),
    "Scenario practicability" = ~format(round(., 2), nsmall = 2),
    "Study realism" = ~format(round(., 2), nsmall = 2),
    "Criteria understandability" = ~format(round(., 2), nsmall = 2),
    "Perceived fun" = ~format(round(., 2), nsmall = 2)) |>
  set_table_properties(layout = "autofit") |>
  color(part = "header", color = "white") |>
  bg(part = "header", bg = "gray") |>
  align(align = "center", part = "all")

print(survey_feedback_table)

```

## Removal of data not being used further in the analysis 

```{r}
data <- data |>
  select(-c(scenexp)) |>
  select(-c(scenpract)) |>
  select(-c(studreal)) |>
  select(-c(critund)) |>
  select(-c(fun)) |>
  select(-c(education)) |>
  select(-c(role)) |>
  select(-c(compact)) |>
  select(-c(busexp)) |>
  select(-c(amountfound)) |>
  select(-c(compfound)) |>
  select(-c(compage)) |>
  select(-c(compcity)) |>
  select(-c(bogus1)) |>
  select(-c(sudoku)) |>
  select(-c(evaluation_bogus3)) |>
  select(-c(bogus3)) |>
  select(-c(amountemp)) |>
  select(-c(duration)) 

```
















# Analysis of measured variables

To control the findings of our conjoint experiment with different potential influencing factors, we included the earlier described demographic information as well as different constructs, that theoretically could have a moderating influence. These latent variables are:

- General Trust Scale explained by 6 items (Yamagishi & Yamagishi, 1994)
- Self-Interest explained by 3 items (De Dreu & Nauta, 2009)
- Other Orientation explained by 3 items (De Dreu & Nauta, 2009)
- Exchange Orientation explained by 9 items (Clark & Mills, 2012)
- Entrepreneurial Self-Efficacy explained by 4 items (Zhao et al., 2005)
- Entrepreneurial Passion by passion for inventing (explained by 4 items for intense positive feelings towards inventing and 1 item for identity centrality for inventing), passion for founding (explained by 3 items for intense positive feelings towards founding and 1 item for identity centrality for founding) and passion for developing (explained by 3 items for intense positive feelings towards developing and 1 item for identity centrality for developing) (Cardon et al. 2013)

## Confirmatory factor analysis

Subsequently we conduct a confirmatory factor analysis (CFA) to evaluate the factor loadings on the latent vaiables and to test the model fit.

### Description of CFA model


```{r}

# Score reversion of exchange orientation items as indicated by the original scales (Clark & Mills, 2012)

data <- data |>
  mutate(  exor3 = 8 - exor3,
    exor4 = 8 - exor4,
    exor5 = 8 - exor5,
    exor9 = 8 - exor9
  ) 

# CFA model

cfa_model <- "gen_trust =~ gentrust1 + gentrust2 + gentrust1 + gentrust4 + gentrust5 + gentrust6
              self_int =~ selfint1 + selfint2 + selfint3
              oth_ori =~ othori1 + othori2 + othori3
              ex_or =~ exor1 + exor2 + exor3 + exor4 + exor5 + exor6 + exor7 + exor8 + exor9
              ese =~ ese1 + ese2 + ese3 + ese4
              ipf_inv =~ ipfinv1 + ipfinv2 + ipfinv3 + ipfinv4
              ic_inv =~ icinv
              ipf_fnd =~ ipffnd1 + ipffnd2 + ipffnd3 + ipffnd1
              ic_fnd =~ icfnd
              ipf_dev =~ ipfdev1 + ipfdev2 + ipfdev3
              ic_dev =~ icdev
              ep_inv =~ ipf_inv + ic_inv
              ep_fnd =~ ipf_fnd + ic_fnd
              ep_dev =~ ipf_dev +   ic_dev
              ep =~ ep_inv + ep_fnd + ep_dev"
                
```



### Model fit information

```{r}

cfa_fit <- cfa(cfa_model, data = data)

summary(cfa_fit, fit.measures = TRUE)

```

### Standardization of results

```{r}

cfa_fit <- standardizedsolution(cfa_fit)

summary(cfa_fit, fit.measures = TRUE)

```

### CFA: Results Overview in a table

```{r}

cfa_fit <- cfa_fit |>
  filter(op == "=~") |>
  select(latent_var = lhs, indicators = rhs, std_loading = est.std ) |>
  mutate(std_loading = round(std_loading, 2))

cfa_fit_table <- flextable(cfa_fit) |>
  autofit() |>
  color(part = "header", color = "white") |>
  bg(part = "header", bg = "gray") |>
  align(align = "center", part = "all") |>
  fontsize(size = 12, part = "all")

print(cfa_fit_table)

```

## Aggregation of indicators to composites

### Calculating the composites

```{r}
data <- data |>
  rowwise() |>
  mutate(gen_trust = mean(c(gentrust1, gentrust2, gentrust3, gentrust4, gentrust5, gentrust6))) |>
  mutate(self_int = mean(c(selfint1, selfint2, selfint3))) |>
  mutate(oth_ori = mean(c(othori1, othori2, othori3))) |>
  mutate(ex_or = mean(c(exor1, exor2, exor3, exor4, exor5, exor6, exor7, exor8, exor9))) |>
  mutate(ese = mean(c(ese1, ese2, ese3, ese4))) |>
  mutate(ipf_inv = mean(c(ipfinv1, ipfinv2, ipfinv3, ipfinv4))) |>
  mutate(ic_inv = mean(c(icinv))) |>
  mutate(ipf_dev = mean(c(ipfdev1, ipfdev2, ipfdev3))) |>
  mutate(ic_dev = mean(c(icdev))) |>
  mutate(ipf_fnd = mean(c(ipffnd1, ipffnd2, ipffnd3))) |>
  mutate(ic_fnd = mean(c(icfnd))) |>
  mutate(ep_inv = mean(c(ipf_inv, ic_inv))) |>
  mutate(ep_fnd = mean(c(ipf_fnd, ic_fnd))) |>
  mutate(ep_dev = mean(c(ipf_dev, ic_dev))) |>
  mutate(ep = mean(c(ep_inv, ep_fnd, ep_dev))) |>
  ungroup()
  
```

### Removing the indicators from the dataset

```{r}

data <- data |>
  select(-c(gentrust1, gentrust2, gentrust3, gentrust4, gentrust5, gentrust6)) |>
  select(-c(selfint1, selfint2, selfint3)) |>
  select(-c(othori1, othori2, othori3)) |>
  select(-c(exor1, exor2, exor3, exor4, exor5, exor6, exor7, exor8, exor9)) |>
  select(-c(ese1, ese2, ese3, ese4)) |>
  select(-c(ipfinv1, ipfinv2, ipfinv3, ipfinv4)) |>
  select(-c(icinv)) |>
  select(-c(ipfdev1, ipfdev2, ipfdev3)) |>
  select(-c(icdev)) |>
  select(-c(ipffnd1, ipffnd2, ipffnd3)) |>
  select(-c(icfnd)) 

```













# Conjoint experiment

## Fractional Factorial Design 

Here, we provide you with the factorial design of this conjoint study: Subsequently the factorial design of the conducted conjoint study will be explained: 

  * 6 attributes
    **ee_support_reception = Perceived EE support
    **ee_affiliation = Affiliation to the EE
    **ee_relationships = Personal Relationship to EE actors
    **altruism_potential = Altruistic potential
    **positive_outcome_expectation = Expected positive outcome of the activity
    **benefit_perception = Perceived benefits of the entrepreneur
  * 2 levels per attribute (0 = low; 1 = high)
  * Fractional design with main-effects only  -> 8 profiles
  * Full replication of all 8 profiles -> 16 profiles
  * Dependent variable = eecontlikex = likelihood to engage in the EE contribution behavior

```{r}
# Levels of all 8 profiles (Orthoplan)

profiles <- tibble(
  profile = c(1, 2, 3, 4, 5, 6, 7, 8),
  ee_support_reception = c(1, 0, 1, 0, 0, 1, 0, 1),
  ee_affiliation = c(0, 1, 1, 0, 1, 0, 0, 1),
  ee_relationships = c(0, 1, 0, 0, 0, 1, 1, 1),
  altruism_potential = c(0, 0, 1, 1, 0, 0, 1, 1),
  positive_outcome_expectation = c(0, 0, 0, 1, 1, 1, 0, 1),
  benefit_perception = c(1, 1, 0, 1, 0, 0, 0, 1)
)
```

### First round of data collection in the conjoint experiment

  *Included variables:
    **respondent_id
    **age
    **gender
    **pubfund
    **programpart
    **startupcenter
    **eecontlike1 to eecontlike8
    **[CFA Factors]


```{r}

first_round_data <- data |>
  select(1:14) # Selecting data from first collection round

first_round_data <- first_round_data |>
  pivot_longer(!c(1:6), # pivoting the data set to a long format
    names_to = "profile", # bringing profile numbers to profile column
    values_to = "eecontlike") |> # bringing eecontlike values to eecontlike column
  mutate(profile = as.numeric(str_extract(profile, "\\-*\\d+\\.*\\d*"))) |> # saving numeric values of profile numbers into the profile column
  mutate(round_id = 1) |> # adding round 1 id
  relocate(round_id, profile, eecontlike, .after = respondent_id) # adjusting column order

```

### Second round of data collection in the conjoint experiment

  *Included variables:
    **respondent_id
    **age
    **gender
    **pubfund
    **programpart
    **startupcenter
    **eecontlike1rep to eecontlike8rep
    **[CFA Factors]


```{r}

second_round_data <- data |>
  select(1:6, 15:22) # Selecting data from second collection round

second_round_data <- second_round_data |>
  pivot_longer(!c(1:6), # pivoting the data set to a long format
    names_to = "profile", # bringing profile numbers to profile column
    values_to = "eecontlike") |> # bringing eecontlike values to eecontlike column
  mutate(profile = as.numeric(str_extract(profile, "\\-*\\d+\\.*\\d*"))) |> # saving numeric values of profile numbers into the profile column
  mutate(round_id = 2) |> # adding round 1 id
  relocate(round_id, profile, eecontlike, .after = respondent_id) # adjusting column order

```

### Merging both reounds of data collection

```{r}
data <- rbind(first_round_data, second_round_data)
```

### Merging factorial design

```{r}
data <- left_join(data, profiles, by = "profile") |> 
  relocate("ee_support_reception", "ee_affiliation", "ee_relationships", "altruism_potential", "positive_outcome_expectation", "benefit_perception", .after = "profile") #relocating attributes in the data set

```

### Converting id and round variables from a numeric format into factors

```{r}

data <- data |>
   mutate(respondent_id = as_factor(respondent_id)) |>
   mutate(round_id = as_factor(round_id))

```


## Evaluation of data consistency

Due to the nature of conjoint studies with complex and theoretically derived scenarios, the potential uncertainity, ambiguity and eventually careless responses is high (Lohrke, 2010). In order to test response consistency, we replicated all 8 profiles of our fractional factorial design (Shepherd & Zacharakis, 2018). Using the data sets from both data collection rounds, we can test the stability of responses applying test-retest reliability assesment.

To evaluate test-retest reliability, we follow the subsequent workflow proposed by Schueler et al. (2023):

1. Calculation of the Intraclass Correlation Coefficient (ICC) for each decision profile
2. Estimation of a linear model with clustered standard errors
3. Calculation of a slope difference test for each parameter
4. Specification of a fully pooled model using both rounds of data with two-way clustered standard errors for both, round and respondent

### Step 1: Calculation of ICC Values for Each Profile

#### Profile 1

##### Profile 1: Transfering data from long to wide format

```{r}

profile1_data <- data |>
  filter(profile == 1) |>
  select(respondent_id, round_id, eecontlike) |> 
  pivot_wider(id_cols = respondent_id, names_prefix = "Round", 
              names_from = round_id, values_from = eecontlike) |>
  select(-respondent_id)

```

##### Profile 1: Calculating ICC (3,k)

```{r}

profile1_icc <- ICC(profile1_data)$results |> 
  filter(type == "ICC3k") |> 
  select(ICC, "lower bound", "upper bound") |>  
  mutate_all(round, 2) %>% 
  remove_rownames(.) %>% 
  add_column(Profile = "Profile 1", .before = "ICC")
profile1_icc

```


#### Profile 2

##### Profile 2: Transfering data from long to wide format

```{r}

profile2_data <- data |>
  filter(profile == 2) |>
  select(respondent_id, round_id, eecontlike) |> 
  pivot_wider(id_cols = respondent_id, names_prefix = "Round", 
              names_from = round_id, values_from = eecontlike) |>
  select(-respondent_id)
```

##### Profile 2: Calculating ICC (3,k)

```{r}

profile2_icc <- ICC(profile2_data)$results |> 
  filter(type == "ICC3k") |> 
  select(ICC, "lower bound", "upper bound") |>  
  mutate_all(round, 2) %>%  
  remove_rownames(.) %>% 
  add_column(Profile = "Profile 2", .before = "ICC")
profile2_icc

```

#### Profile 3

##### Profile 3: Transfering data from long to wide format

```{r}

profile3_data <- data |>
  filter(profile == 3) |>
  select(respondent_id, round_id, eecontlike) |> 
  pivot_wider(id_cols = respondent_id, names_prefix = "Round", 
              names_from = round_id, values_from = eecontlike) |>
  select(-respondent_id)
```

##### Profile 3: Calculating ICC (3,k)

```{r}

profile3_icc <- ICC(profile3_data)$results |> 
  filter(type == "ICC3k") |> 
  select(ICC, "lower bound", "upper bound") |>  
  mutate_all(round, 2) %>%
  remove_rownames(.) %>% 
  add_column(Profile = "Profile 3", .before = "ICC")
profile3_icc

```

#### Profile 4

##### Profile 4: Transfering data from long to wide format

```{r}

profile4_data <- data |>
  filter(profile == 4) |>
  select(respondent_id, round_id, eecontlike) |> 
  pivot_wider(id_cols = respondent_id, names_prefix = "Round", 
              names_from = round_id, values_from = eecontlike) |>
  select(-respondent_id)
```

##### Profile 4: Calculating ICC (3,k)

```{r}

profile4_icc <- ICC(profile4_data)$results |> 
  filter(type == "ICC3k") |> 
  select(ICC, "lower bound", "upper bound") |>  
  mutate_all(round, 2) %>%  
  remove_rownames(.) %>% 
  add_column(Profile = "Profile 4", .before = "ICC")
profile4_icc

```

#### Profile 5

##### Profile 5: Transfering data from long to wide format

```{r}

profile5_data <- data |>
  filter(profile == 5) |>
  select(respondent_id, round_id, eecontlike) |> 
  pivot_wider(id_cols = respondent_id, names_prefix = "Round", 
              names_from = round_id, values_from = eecontlike) |>
  select(-respondent_id)
```

##### Profile 5: Calculating ICC (3,k)

```{r}

profile5_icc <- ICC(profile5_data)$results |> 
  filter(type == "ICC3k") |> 
  select(ICC, "lower bound", "upper bound") |>  
  mutate_all(round, 2) %>%  
  remove_rownames(.) %>% 
  add_column(Profile = "Profile 5", .before = "ICC")
profile5_icc

```

#### Profile 6

##### Profile 6: Transfering data from long to wide format

```{r}

profile6_data <- data |>
  filter(profile == 6) |>
  select(respondent_id, round_id, eecontlike) |> 
  pivot_wider(id_cols = respondent_id, names_prefix = "Round", 
              names_from = round_id, values_from = eecontlike) |>
  select(-respondent_id)
```

##### Profile 6: Calculating ICC (3,k)

```{r}

profile6_icc <- ICC(profile6_data)$results |> 
  filter(type == "ICC3k") |> 
  select(ICC, "lower bound", "upper bound") |>  
  mutate_all(round, 2) %>%  
  remove_rownames(.) %>% 
  add_column(Profile = "Profile 6", .before = "ICC")
profile6_icc

```

#### Profile 7

##### Profile 7: Transfering data from long to wide format

```{r}

profile7_data <- data |>
  filter(profile == 7) |>
  select(respondent_id, round_id, eecontlike) |> 
  pivot_wider(id_cols = respondent_id, names_prefix = "Round", 
              names_from = round_id, values_from = eecontlike) |>
  select(-respondent_id)
```

##### Profile 7: Calculating ICC (3,k)

```{r}

profile7_icc <- ICC(profile7_data)$results |> 
  filter(type == "ICC3k") |> 
  select(ICC, "lower bound", "upper bound") |>  
  mutate_all(round, 2) %>% 
  remove_rownames(.) %>% 
  add_column(Profile = "Profile 7", .before = "ICC")
profile7_icc

```

#### Profile 8

##### Profile 8: Transfering data from long to wide format

```{r}

profile8_data <- data |>
  filter(profile == 8) |>
  select(respondent_id, round_id, eecontlike) |> 
  pivot_wider(id_cols = respondent_id, names_prefix = "Round", 
              names_from = round_id, values_from = eecontlike) |>
  select(-respondent_id)
```

##### Profile 8: Calculating ICC (3,k)

```{r}

profile8_icc <- ICC(profile8_data)$results |> 
  filter(type == "ICC3k") |> 
  select(ICC, "lower bound", "upper bound") |>  
  mutate_all(round, 2) %>%  
  remove_rownames(.) %>% 
  add_column(Profile = "Profile 8", .before = "ICC")
profile8_icc

```

#### ICC Summary Table

The summary table includes the ICC value itself and a 95% confidence interval to better understand the underlying variance in response consistency. 

```{r}
# We collect all the previous rounds to display in a single data frame/table
bind_rows(profile1_icc,
          profile2_icc,
          profile3_icc,
          profile4_icc,
          profile5_icc,
          profile6_icc,
          profile7_icc,
          profile8_icc)
```














## Correlation Table

The correlation table of the model includes the dependent variable, controls as well as significant factors from the CFA. These are:

  *eecontlike
  *age
  *gender
  *pubfund
  *programpart
  *startupcenter
  *[CFA Factors]


```{r}

data |>
  select(eecontlike, age, gender, pubfund, programpart, startupcenter) |> #selecting variables
  apa.cor.table() #creation of correlation matrix

```

## Regression Model

The following regression modell represents a multilevel modell, as conjoint profiles were answered twice in two seperat rounds. 

We will include the earlier specified and listed variables.


### Model fitting

The linear regression model includes the following variables:

* Dependent variable: eecontlike = likelihood to engage in the EE contribution behavior
* Independent variables:
    **ee_support_reception = Perceived EE support
    **ee_affiliation = Affiliation to the EE
    **ee_relationships = Personal Relationship to EE actors
    **altruism_potential = Altruistic potential
    **positive_outcome_expectation = Expected positive outcome of the activity
    **benefit_perception = Perceived benefits of the entrepreneur
* Control variables:
    **age
    **gender
    **pubfund
    **programpart
    **startupcenter
    **CFA Factors
* Nesting variable: respondent_id

```{r}

res <- lmer(eecontlike ~ ee_support_reception + ee_affiliation + ee_relationships + altruism_potential + positive_outcome_expectation + benefit_perception + (1|respondent_id), REML = TRUE, data = data)

```


### Extracting Model Fit


```{r}

model_fit <- glance(res) # Extracting model fit

r2 <- r2_nakagawa(res, by_group = TRUE) # Computing R2

icc <- icc(res, by_group = TRUE) # Computing ICC 

# Creation of a fit table 
model_fit <- tibble(
  Variable = c(
    "R2 Level 1",
    "R2 Level 2",
    "ICC",
    "Sigma",
    "Decisions",
    "Respondents"),
      "B (β)" = c(
         round(r2$R2[1], 2),
         round(r2$R2[2], 2),
         round(icc$ICC[1],2),
        round(model_fit$sigma, 3),
        model_fit$nobs, length(unique(data$respondent_id))),
    SE = c(NA_real_, NA_real_, NA_real_, NA_real_, NA_real_, NA_real_),
    `t-ratio` = c(NA_real_, NA_real_, NA_real_, NA_real_, NA_real_, NA_real_),
     `p-value` = c(NA_real_, NA_real_, NA_real_, NA_real_, NA_real_, NA_real_)
)
```

### Standardize Coefficients

Subsequently we compute the standardized regression coefficients:

```{r}
# Obtaining standardized parameters
res_std <- standardize_parameters(res, method = "posthoc")

# Selecting standardized coefficients (rounded to 2 digits)

res_std <- res_std |>
  select(Std_Coefficient) |>
  mutate(Std_Coefficient = round(Std_Coefficient, 2))

```

### Cluster Robust Standard Errors

Subsequently we compute the cluster robust standard errors (SE) to allow for correlation between observations within clusters. This means we nest the 16 responses per respondent within respondent_ids.

Use the the "model_parameters" function ("parameters" package) to obtain cluster robust standard errors:

* vcov should be "vcovCR"
* vcov_args pick "CR1" for type and "dat$respondent_id" for cluster

```{r}
res <- model_parameters(res,
                        vcov = "vcovCR",
                        vcov_args = list(type = "CR1", cluster = data$respondent_id)
                        ) 

head(res)

```

## Prepring final output

```{r}
# Creating coefficient variable
res <- res |>
  mutate("B (β)" = paste0(B, " (", Std_Coefficient, ")")) |>
  select(-c(B, Std_Coefficient)) |>
  relocate("B (β)", .after = Variable)

# Combining result and fit tables
res <- rbind(res, model_fit)

# Renaming variables
res <- res |>
  mutate(Variable = if_else(Variable == "(Intercept)", "Intercept", Variable)) |>
  mutate(Variable = if_else(Variable == "ee_support_reception", "Perceived EE support", Variable)) |>
  mutate(Variable = if_else(Variable == "ee_affiliation", "Affiliation to the EE", Variable)) |>
  mutate(Variable = if_else(Variable == "ee_relationships", "Personal Relationship to EE actors", Variable)) |>
  mutate(Variable = if_else(Variable == "altruism_potential", "Altruistic potential", Variable)) |>
  mutate(Variable = if_else(Variable == "positive_outcome_expectation", "Expected positive outcome", Variable)) |>
  mutate(Variable = if_else(Variable == "benefit_perception", "Perceived benefits", Variable)) |>
  mutate(Variable = if_else(Variable == "age", "Age", Variable)) |>
  mutate(Variable = if_else(Variable == "gender", "Gender", Variable)) |>
  mutate(Variable = if_else(Variable == "pubfund", "Publicly funded", Variable)) |> 
  mutate(Variable = if_else(Variable == "programpart", "Program participation", Variable)) |>
  mutate(Variable = if_else(Variable == "startupcenter", "Startup center", Variable)) 
 
```

## Displaying Table

Use the flextable package to create a table with chained pipes:

* The "autofit()" function may come in handy
* Use "align" to right flush text of the 2nd column in the header
* Use "align" to right flush text of the 2nd column in the body
* Put a horizontal line below the footer "hline_bottom"
* Set the font to "Times New Roman" and fontsize to 12
* Output the table to word

```{r}

```
